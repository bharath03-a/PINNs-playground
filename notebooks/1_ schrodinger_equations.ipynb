{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "361222ea",
   "metadata": {},
   "source": [
    "**NOTE:** The below implementation is highly inspired from he PINN paper from 2019 and their open source repository, the data and model architecture has been referenced from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f5a7d45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.io\n",
    "from pyDOE import lhs\n",
    "\n",
    "import time\n",
    "import tqdm\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac46a09",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "eafbf94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain boundaries\n",
    "\n",
    "x_min, x_max = -5.0, 5.0\n",
    "t_min, t_max = 0.0, np.pi/2\n",
    "\n",
    "lb = np.array([x_min, t_min])\n",
    "ub = np.array([x_max, t_max])\n",
    "\n",
    "# lb - lower bound, ub - upper bound\n",
    "\n",
    "N0 = 20\n",
    "N_b = 20\n",
    "N_f = 10000\n",
    "\n",
    "# N0 - number of points in the initial condition, \n",
    "# N_b - number of points in the boundary condition, \n",
    "# N_f - number of points in the interior domain\n",
    "\n",
    "layers = [2, 50, 50, 50, 50, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7391921b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scipy.io.loadmat('../data/NLS.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bd98a075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__header__', '__version__', '__globals__', 'tt', 'uu', 'x']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ef2711",
   "metadata": {},
   "source": [
    "`tt` - Time Grid\n",
    "\n",
    "`uu` - Full Solution Array\n",
    "\n",
    "`x` - Spatial Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8dee1715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of time grid: (1, 201)\n",
      "Shape of solution array: (256, 201)\n",
      "Shape of spatial grid: (1, 256)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of time grid: {data['tt'].shape}\")\n",
    "print(f\"Shape of solution array: {data['uu'].shape}\")\n",
    "print(f\"Shape of spatial grid: {data['x'].shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bea42fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = data['tt'].flatten()[:, None]\n",
    "x = data['x'].flatten()[:, None]\n",
    "Exact = data['uu']\n",
    "Exact_u = np.real(Exact)\n",
    "Exact_v = np.imag(Exact)\n",
    "\n",
    "Exact_h_modulus = np.sqrt(Exact_u**2 + Exact_v**2)\n",
    "\n",
    "# h = u + iv\n",
    "# h_modulus = sqrt(u^2 + v^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a0a100e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of exact solution: (256, 201)\n",
      "Shape of time grid: (201, 1)\n",
      "Shape of spatial grid: (256, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of exact solution: {Exact.shape}\")\n",
    "print(f\"Shape of time grid: {t.shape}\")\n",
    "print(f\"Shape of spatial grid: {x.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "25b92aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of u_star: (51456, 1)\n",
      "Shape of v_star: (51456, 1)\n",
      "Shape of h_star: (51456, 1)\n",
      "Shape of X_star: (51456, 2)\n"
     ]
    }
   ],
   "source": [
    "X, T = np.meshgrid(x, t)\n",
    "\n",
    "X_star = np.hstack((X.flatten()[:, None], T.flatten()[:, None]))\n",
    "\n",
    "u_star = Exact_u.flatten()[:, None]\n",
    "v_star = Exact_v.flatten()[:, None]\n",
    "h_star = Exact_h_modulus.flatten()[:, None]\n",
    "\n",
    "print(f\"Shape of u_star: {u_star.shape}\")\n",
    "print(f\"Shape of v_star: {v_star.shape}\")\n",
    "print(f\"Shape of h_star: {h_star.shape}\")\n",
    "print(f\"Shape of X_star: {X_star.shape}\")\n",
    "\n",
    "# X_star - spatial and temporal grid\n",
    "# u_star - real part of the solution\n",
    "# v_star - imaginary part of the solution\n",
    "# h_star - modulus of the solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d39340bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_x = np.random.choice(x.shape[0], N0, replace=False)\n",
    "\n",
    "x0 = x[idx_x,:]\n",
    "u0 = Exact_u[idx_x,0:1]\n",
    "v0 = Exact_v[idx_x,0:1]\n",
    "\n",
    "idx_t = np.random.choice(t.shape[0], N_b, replace=False)\n",
    "t_b = t[idx_t,:]\n",
    "\n",
    "X_f = lb + (ub - lb) * lhs(2, N_f)\n",
    "\n",
    "# x0 - selected x points from the initial condition where t = 0\n",
    "# u0 - real part of the initial condition\n",
    "# v0 - imaginary part of the initial condition\n",
    "\n",
    "\n",
    "# t_b - time values at which the spatial boundaries will be sampled.\n",
    "# X_f - interior points (xf, tf) used to enforce the PDE via the residuals f_u and f_v.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264abb62",
   "metadata": {},
   "source": [
    "`lhs(2, N_f)`: Latin Hypercube Sampling of 2D space ([0,1]^2) to get N_f points.\n",
    "\n",
    "| Set                       | How sampled                     | Domain             | Purpose                           |\n",
    "| ------------------------- | ------------------------------- | ------------------ | --------------------------------- |\n",
    "| `x0, u0, v0`              | random `N0` spatial points      | t=0                | **initial condition**             |\n",
    "| `tb` (used in X_lb, X_ub) | random `Nb` time points         | x=lb, ub           | **boundary condition**            |\n",
    "| `X_f`                     | `Nf` points via Latin Hypercube | interior 2D domain | **collocation / PDE enforcement** |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f541825",
   "metadata": {},
   "source": [
    "Now that the data preparation is complete, we move on to **modeling the neural network**. \n",
    "\n",
    "- The datasets `x0`, `u0`, `v0`, `tb`, and `X_f` are used to **compute the PINN’s loss function** during training:\n",
    "\n",
    "  - **Initial condition points** (`x0`, `u0`, `v0`):  \n",
    "    These are spatial points at \\(t=0\\) and enforce the initial state of the system.\n",
    "\n",
    "  - **Boundary condition points** (`tb`, `lb`, `ub`):  \n",
    "    These correspond to time points at the spatial boundaries and enforce constraints at the edges of the domain.\n",
    "\n",
    "  - **Collocation points** (`X_f`):  \n",
    "    These are points in the interior of the domain where the PDE residuals are enforced, ensuring the neural network satisfies the governing equations.\n",
    "\n",
    "- The `_star` datasets (e.g., `X_star`, `u_star`, `v_star`, `h_star`) represent the **full reference solution on a dense grid**, which is used for **prediction, evaluation, and error computation** after training. These points are **not used in computing the loss**, but serve as a benchmark to assess the accuracy of the network’s predictions.\n",
    "\n",
    "**Summary:**  \n",
    "- `x0, u0, v0, tb, X_f` → **training points** used to enforce physics, initial, and boundary conditions.  \n",
    "- `_star` values → **evaluation points** used to validate the model’s performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3dcd638d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the PINN model\n",
    "\n",
    "class PhysicsInformedNN(tf.keras.Model):\n",
    "    # Initialize the PINN model\n",
    "    def __init__(self, x0, u0, v0, tb, lb, ub, X_f, layers, lr):\n",
    "        \"\"\"\n",
    "        Initialize the PhysicsInformedNN model.\n",
    "\n",
    "        Args:\n",
    "            x0 (np.ndarray): Initial spatial points\n",
    "            u0 (np.ndarray): Initial real part of solution\n",
    "            v0 (np.ndarray): Initial imaginary part of solution\n",
    "            tb (np.ndarray): Boundary time points\n",
    "            lb (np.ndarray): Lower spatial boundary\n",
    "            ub (np.ndarray): Upper spatial boundary\n",
    "            X_f (np.ndarray): Collocation points\n",
    "            layers (list): List of layer sizes for the neural network\n",
    "            lr (float): Learning rate for the optimizer\n",
    "        \"\"\"  \n",
    "        super(PhysicsInformedNN, self).__init__()\n",
    "        self.layer_sizes = layers\n",
    "        self.lr = lr\n",
    "        \n",
    "        # what are we predicting?\n",
    "        # u,v at initial condition (u0, v0)\n",
    "        # u,v at boundary (u_lb, v_lb, u_ub, v_ub)\n",
    "        # f_u, f_v at interior points (f_u_int, f_v_int)\n",
    "        \n",
    "        # constructing input data for the model for all the above conditions\n",
    "\n",
    "        X0 = np.concatenate((x0, np.zeros_like(x0)), 1) # (x0, t=0)\n",
    "        X_lb = np.concatenate((lb[0]*np.ones_like(tb), tb), 1) # (x=lb, t)\n",
    "        X_ub = np.concatenate((ub[0]*np.ones_like(tb), tb), 1) # (x=ub, t)\n",
    "        \n",
    "        self.lb = tf.constant(lb, dtype=tf.float32)\n",
    "        self.ub = tf.constant(ub, dtype=tf.float32)\n",
    "        self.u0 = tf.constant(u0, dtype=tf.float32)\n",
    "        self.v0 = tf.constant(v0, dtype=tf.float32)\n",
    "        \n",
    "        self.x0 = tf.constant(X0[:,0:1], dtype=tf.float32)\n",
    "        self.t0 = tf.constant(X0[:,1:2], dtype=tf.float32)\n",
    "        self.x_lb = tf.constant(X_lb[:,0:1], dtype=tf.float32)\n",
    "        self.t_lb = tf.constant(X_lb[:,1:2], dtype=tf.float32)\n",
    "        self.x_ub = tf.constant(X_ub[:,0:1], dtype=tf.float32)\n",
    "        self.t_ub = tf.constant(X_ub[:,1:2], dtype=tf.float32)\n",
    "\n",
    "        self.x_f = tf.constant(X_f[:,0:1], dtype=tf.float32)\n",
    "        self.t_f = tf.constant(X_f[:,1:2], dtype=tf.float32)\n",
    "\n",
    "        self.hidden_layers = [tf.keras.layers.Dense(layer, activation='tanh') for layer in self.layer_sizes[1:-1]]\n",
    "        self.output_layer = tf.keras.layers.Dense(self.layer_sizes[-1])\n",
    "\n",
    "        self.optimizer = tf.optimizers.Adam(self.lr)\n",
    "        \n",
    "        # Build the model by calling it with dummy data to initialize trainable_variables\n",
    "        dummy_input = tf.zeros((1, 2), dtype=tf.float32)\n",
    "        _ = self.call(dummy_input)\n",
    "\n",
    "        \n",
    "    def call(self, X):\n",
    "        \"\"\"Forward pass through the neural network.\"\"\"\n",
    "        H = 2.0 * (X - self.lb) / (self.ub - self.lb) - 1.0\n",
    "        for layer in self.hidden_layers:\n",
    "            H = layer(H)\n",
    "\n",
    "        Y = self.output_layer(H)\n",
    "\n",
    "        return Y\n",
    "\n",
    "    def net_uv(self, x, t):\n",
    "        \"\"\"Get u, v and their spatial derivatives.\"\"\"\n",
    "        # Create a single variable for the input\n",
    "        X = tf.concat([x, t], 1)\n",
    "        X_var = tf.Variable(X, dtype=tf.float32)\n",
    "\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            tape.watch(X_var)\n",
    "            uv = self.call(X_var)\n",
    "            u = uv[:, 0:1]\n",
    "            v = uv[:, 1:2]\n",
    "\n",
    "        # Compute first derivatives with respect to the full input\n",
    "        u_grad = tape.gradient(u, X_var)\n",
    "        v_grad = tape.gradient(v, X_var)\n",
    "\n",
    "        # Extract spatial and temporal derivatives\n",
    "        u_x = u_grad[:, 0:1] if u_grad is not None else tf.zeros_like(x)\n",
    "        v_x = v_grad[:, 0:1] if v_grad is not None else tf.zeros_like(x)\n",
    "        u_t = u_grad[:, 1:2] if u_grad is not None else tf.zeros_like(t)\n",
    "        v_t = v_grad[:, 1:2] if v_grad is not None else tf.zeros_like(t)\n",
    "\n",
    "        # Compute second derivatives\n",
    "        u_xx = tape.gradient(u_x, X_var)\n",
    "        v_xx = tape.gradient(v_x, X_var)\n",
    "        \n",
    "        # Extract second spatial derivatives\n",
    "        u_xx = u_xx[:, 0:1] if u_xx is not None else tf.zeros_like(x)\n",
    "        v_xx = v_xx[:, 0:1] if v_xx is not None else tf.zeros_like(x)\n",
    "\n",
    "        del tape\n",
    "\n",
    "        return u, v, u_x, v_x, u_t, v_t, u_xx, v_xx\n",
    "\n",
    "    def net_f_uv(self, x, t):\n",
    "        \"\"\"Compute PDE residuals.\"\"\"\n",
    "        u, v, u_x, v_x, u_t, v_t, u_xx, v_xx = self.net_uv(x, t)\n",
    "\n",
    "        f_u = u_t + 0.5*v_xx + (u**2 + v**2)*v\n",
    "        f_v = v_t - 0.5*u_xx - (u**2 + v**2)*u\n",
    "\n",
    "        return f_u, f_v\n",
    "    \n",
    "    def get_trainable_variables_info(self):\n",
    "        \"\"\"Get information about trainable variables.\"\"\"\n",
    "        print(f\"Number of trainable variables: {len(self.trainable_variables)}\")\n",
    "        for i, var in enumerate(self.trainable_variables):\n",
    "            print(f\"Variable {i}: shape {var.shape}, name {var.name}\")\n",
    "        return self.trainable_variables\n",
    "    \n",
    "\n",
    "    \n",
    "    def train(self, iterations):\n",
    "        \"\"\"Training loop for the PINN model.\"\"\"\n",
    "\n",
    "        start_time = time.time()\n",
    "        for i in range(iterations):\n",
    "            with tf.GradientTape() as tape:\n",
    "                # forward pass\n",
    "                u0_pred, v0_pred, u0_x, v0_x, u0_t, v0_t, u0_xx, v0_xx = self.net_uv(self.x0, self.t0)\n",
    "                u_lb_pred, v_lb_pred, u_lb_x, v_lb_x, u_lb_t, v_lb_t, u_lb_xx, v_lb_xx = self.net_uv(self.x_lb, self.t_lb)\n",
    "                u_ub_pred, v_ub_pred, u_ub_x, v_ub_x, u_ub_t, v_ub_t, u_ub_xx, v_ub_xx = self.net_uv(self.x_ub, self.t_ub)\n",
    "                f_u_pred, f_v_pred = self.net_f_uv(self.x_f, self.t_f)\n",
    "\n",
    "                # compute loss\n",
    "                loss_u0 = tf.reduce_mean(tf.square(u0_pred - self.u0))\n",
    "                loss_v0 = tf.reduce_mean(tf.square(v0_pred - self.v0))\n",
    "                loss_bc = tf.reduce_mean(tf.square(u_lb_pred - u_ub_pred)) + tf.reduce_mean(tf.square(v_lb_pred - v_ub_pred))\n",
    "                loss_bc_x = tf.reduce_mean(tf.square(u_lb_x - u_ub_x)) + tf.reduce_mean(tf.square(v_lb_x - v_ub_x))\n",
    "                loss_f = tf.reduce_mean(tf.square(f_u_pred)) + tf.reduce_mean(tf.square(f_v_pred))\n",
    "\n",
    "                loss = loss_u0 + loss_v0 + loss_bc + loss_bc_x + loss_f\n",
    "            \n",
    "            grads = tape.gradient(loss, self.trainable_variables)\n",
    "            self.optimizer.apply_gradients(zip(grads, self.trainable_variables))\n",
    "\n",
    "            if i % 2 == 0:\n",
    "                elapsed = time.time() - start_time\n",
    "                tqdm.tqdm.write(f\"Iteration {i}, Loss: {loss.numpy()}, Time: {elapsed}\")\n",
    "                start_time = time.time()\n",
    "                try:\n",
    "                    print(f\"Number of trainable variables: {len(self.trainable_variables)}\")\n",
    "                    print(f\"Trainable variables shapes: {[var.shape for var in self.trainable_variables[:5]]}\")  # Show first 5\n",
    "                except Exception as e:\n",
    "                    print(f\"Could not access trainable variables: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ff5900fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "model = PhysicsInformedNN(x0, u0, v0, t_b, lb, ub, X_f, layers, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6fe94226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Loss: 0.7512832283973694, Time: 0.18286609649658203\n",
      "Number of trainable variables: 10\n",
      "Trainable variables shapes: [TensorShape([2, 50]), TensorShape([50]), TensorShape([50, 50]), TensorShape([50]), TensorShape([50, 50])]\n",
      "Iteration 2, Loss: 0.4648878574371338, Time: 0.15547800064086914\n",
      "Number of trainable variables: 10\n",
      "Trainable variables shapes: [TensorShape([2, 50]), TensorShape([50]), TensorShape([50, 50]), TensorShape([50]), TensorShape([50, 50])]\n",
      "Iteration 4, Loss: 0.5005298852920532, Time: 0.15757203102111816\n",
      "Number of trainable variables: 10\n",
      "Trainable variables shapes: [TensorShape([2, 50]), TensorShape([50]), TensorShape([50, 50]), TensorShape([50]), TensorShape([50, 50])]\n",
      "Iteration 6, Loss: 0.41305243968963623, Time: 0.14287614822387695\n",
      "Number of trainable variables: 10\n",
      "Trainable variables shapes: [TensorShape([2, 50]), TensorShape([50]), TensorShape([50, 50]), TensorShape([50]), TensorShape([50, 50])]\n",
      "Iteration 8, Loss: 0.37184715270996094, Time: 0.15427184104919434\n",
      "Number of trainable variables: 10\n",
      "Trainable variables shapes: [TensorShape([2, 50]), TensorShape([50]), TensorShape([50, 50]), TensorShape([50]), TensorShape([50, 50])]\n"
     ]
    }
   ],
   "source": [
    "iterations = 10\n",
    "model.train(iterations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
