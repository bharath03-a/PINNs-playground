{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "361222ea",
   "metadata": {},
   "source": [
    "**NOTE:** The below implementation is highly inspired from he PINN paper from 2019 and their open source repository, the data and model architecture has been referenced from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a7d45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.io\n",
    "from pyDOE import lhs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac46a09",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eafbf94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain boundaries\n",
    "\n",
    "x_min, x_max = -5.0, 5.0\n",
    "t_min, t_max = 0.0, np.pi/2\n",
    "\n",
    "lb = np.array([x_min, t_min])\n",
    "ub = np.array([x_max, t_max])\n",
    "\n",
    "# lb - lower bound, ub - upper bound\n",
    "\n",
    "N0 = 20\n",
    "N_b = 20\n",
    "N_f = 10000\n",
    "\n",
    "# N0 - number of points in the initial condition, \n",
    "# N_b - number of points in the boundary condition, \n",
    "# N_f - number of points in the interior domain\n",
    "\n",
    "layers = [2, 50, 50, 50, 50, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7391921b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scipy.io.loadmat('../data/NLS.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd98a075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__header__', '__version__', '__globals__', 'tt', 'uu', 'x']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ef2711",
   "metadata": {},
   "source": [
    "`tt` - Time Grid\n",
    "\n",
    "`uu` - Full Solution Array\n",
    "\n",
    "`x` - Spatial Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8dee1715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of time grid: (1, 201)\n",
      "Shape of solution array: (256, 201)\n",
      "Shape of spatial grid: (1, 256)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of time grid: {data['tt'].shape}\")\n",
    "print(f\"Shape of solution array: {data['uu'].shape}\")\n",
    "print(f\"Shape of spatial grid: {data['x'].shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bea42fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = data['tt'].flatten()[:, None]\n",
    "x = data['x'].flatten()[:, None]\n",
    "Exact = data['uu']\n",
    "Exact_u = np.real(Exact)\n",
    "Exact_v = np.imag(Exact)\n",
    "\n",
    "Exact_h_modulus = np.sqrt(Exact_u**2 + Exact_v**2)\n",
    "\n",
    "# h = u + iv\n",
    "# h_modulus = sqrt(u^2 + v^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0a100e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of exact solution: (256, 201)\n",
      "Shape of time grid: (201, 1)\n",
      "Shape of spatial grid: (256, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of exact solution: {Exact.shape}\")\n",
    "print(f\"Shape of time grid: {t.shape}\")\n",
    "print(f\"Shape of spatial grid: {x.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25b92aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of u_star: (51456, 1)\n",
      "Shape of v_star: (51456, 1)\n",
      "Shape of h_star: (51456, 1)\n",
      "Shape of X_star: (51456, 2)\n"
     ]
    }
   ],
   "source": [
    "X, T = np.meshgrid(x, t)\n",
    "\n",
    "X_star = np.hstack((X.flatten()[:, None], T.flatten()[:, None]))\n",
    "\n",
    "u_star = Exact_u.flatten()[:, None]\n",
    "v_star = Exact_v.flatten()[:, None]\n",
    "h_star = Exact_h_modulus.flatten()[:, None]\n",
    "\n",
    "print(f\"Shape of u_star: {u_star.shape}\")\n",
    "print(f\"Shape of v_star: {v_star.shape}\")\n",
    "print(f\"Shape of h_star: {h_star.shape}\")\n",
    "print(f\"Shape of X_star: {X_star.shape}\")\n",
    "\n",
    "# X_star - spatial and temporal grid\n",
    "# u_star - real part of the solution\n",
    "# v_star - imaginary part of the solution\n",
    "# h_star - modulus of the solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d39340bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_x = np.random.choice(x.shape[0], N0, replace=False)\n",
    "\n",
    "x0 = x[idx_x,:]\n",
    "u0 = Exact_u[idx_x,0:1]\n",
    "v0 = Exact_v[idx_x,0:1]\n",
    "\n",
    "idx_t = np.random.choice(t.shape[0], N_b, replace=False)\n",
    "t_b = t[idx_t,:]\n",
    "\n",
    "X_f = lb + (ub - lb) * lhs(2, N_f)\n",
    "\n",
    "# x0 - selected x points from the initial condition where t = 0\n",
    "# u0 - real part of the initial condition\n",
    "# v0 - imaginary part of the initial condition\n",
    "\n",
    "\n",
    "# t_b - time values at which the spatial boundaries will be sampled.\n",
    "# X_f - interior points (xf, tf) used to enforce the PDE via the residuals f_u and f_v.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264abb62",
   "metadata": {},
   "source": [
    "`lhs(2, N_f)`: Latin Hypercube Sampling of 2D space ([0,1]^2) to get N_f points.\n",
    "\n",
    "| Set                       | How sampled                     | Domain             | Purpose                           |\n",
    "| ------------------------- | ------------------------------- | ------------------ | --------------------------------- |\n",
    "| `x0, u0, v0`              | random `N0` spatial points      | t=0                | **initial condition**             |\n",
    "| `tb` (used in X_lb, X_ub) | random `Nb` time points         | x=lb, ub           | **boundary condition**            |\n",
    "| `X_f`                     | `Nf` points via Latin Hypercube | interior 2D domain | **collocation / PDE enforcement** |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f541825",
   "metadata": {},
   "source": [
    "Now that the data preparation is complete, we move on to **modeling the neural network**. \n",
    "\n",
    "- The datasets `x0`, `u0`, `v0`, `tb`, and `X_f` are used to **compute the PINN’s loss function** during training:\n",
    "\n",
    "  - **Initial condition points** (`x0`, `u0`, `v0`):  \n",
    "    These are spatial points at \\(t=0\\) and enforce the initial state of the system.\n",
    "\n",
    "  - **Boundary condition points** (`tb`, `lb`, `ub`):  \n",
    "    These correspond to time points at the spatial boundaries and enforce constraints at the edges of the domain.\n",
    "\n",
    "  - **Collocation points** (`X_f`):  \n",
    "    These are points in the interior of the domain where the PDE residuals are enforced, ensuring the neural network satisfies the governing equations.\n",
    "\n",
    "- The `_star` datasets (e.g., `X_star`, `u_star`, `v_star`, `h_star`) represent the **full reference solution on a dense grid**, which is used for **prediction, evaluation, and error computation** after training. These points are **not used in computing the loss**, but serve as a benchmark to assess the accuracy of the network’s predictions.\n",
    "\n",
    "**Summary:**  \n",
    "- `x0, u0, v0, tb, X_f` → **training points** used to enforce physics, initial, and boundary conditions.  \n",
    "- `_star` values → **evaluation points** used to validate the model’s performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcd638d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the PINN model\n",
    "\n",
    "class PhysicsInformedNN:\n",
    "    # Initialize the PINN model\n",
    "    def __init__(self, x0, t0, u0, v0, tb, lb, ub, X_f, layers, lr):\n",
    "        \"\"\"\n",
    "        Initialize the PhysicsInformedNN model.\n",
    "\n",
    "        Args:\n",
    "            x0 (np.ndarray): Initial spatial points\n",
    "            t0 (np.ndarray): Initial time points\n",
    "            u0 (np.ndarray): Initial real part of solution\n",
    "            v0 (np.ndarray): Initial imaginary part of solution\n",
    "            tb (np.ndarray): Boundary time points\n",
    "            lb (np.ndarray): Lower spatial boundary\n",
    "            ub (np.ndarray): Upper spatial boundary\n",
    "            X_f (np.ndarray): Collocation points\n",
    "            layers (list): List of layer sizes for the neural network\n",
    "            lr (float): Learning rate for the optimizer\n",
    "        \"\"\"      \n",
    "        self.layers = layers\n",
    "        self.lr = lr\n",
    "        self.weights, self.biases = self.initialize_NN(layers)\n",
    "        \n",
    "        # what are we predicting?\n",
    "        # u,v at initial condition (u0, v0)\n",
    "        # u,v at boundary (u_lb, v_lb, u_ub, v_ub)\n",
    "        # f_u, f_v at interior points (f_u_int, f_v_int)\n",
    "        \n",
    "        # constructing input data for the model for all the above conditions\n",
    "\n",
    "        X0 = np.concatenate((x0, np.zeros_like(x0)), 1) # (x0, t=0)\n",
    "        X_lb = np.concatenate((lb[0]*np.ones_like(tb), tb), 1) # (x=lb, t)\n",
    "        X_ub = np.concatenate((ub[0]*np.ones_like(tb), tb), 1) # (x=ub, t)\n",
    "        \n",
    "        self.lb = tf.constant(lb, dtype=tf.float32)\n",
    "        self.ub = tf.constant(ub, dtype=tf.float32)\n",
    "        self.u0 = tf.constant(u0, dtype=tf.float32)\n",
    "        self.v0 = tf.constant(v0, dtype=tf.float32)\n",
    "        \n",
    "        self.x0 = tf.constant(X0[:,0:1], dtype=tf.float32)\n",
    "        self.t0 = tf.constant(X0[:,1:2], dtype=tf.float32)\n",
    "        self.x_lb = tf.constant(X_lb[:,0:1], dtype=tf.float32)\n",
    "        self.t_lb = tf.constant(X_lb[:,1:2], dtype=tf.float32)\n",
    "        self.x_ub = tf.constant(X_ub[:,0:1], dtype=tf.float32)\n",
    "        self.t_ub = tf.constant(X_ub[:,1:2], dtype=tf.float32)\n",
    "\n",
    "        self.x_f = tf.constant(X_f[:,0:1], dtype=tf.float32)\n",
    "        self.t_f = tf.constant(X_f[:,1:2], dtype=tf.float32)\n",
    "        \n",
    "    def build_nn(self):\n",
    "        \"\"\"Forward pass through the neural network.\"\"\"\n",
    "        model = tf.keras.Sequential()\n",
    "\n",
    "        model.add(layers.Dense(self.layers[0], input_shape=(2,)))\n",
    "\n",
    "        for i in range(1, len(self.layers)):\n",
    "            model.add(layers.Dense(self.layers[i], activation='tanh'))\n",
    "\n",
    "        model.add(layers.Dense(self.layers[-1]))\n",
    "\n",
    "        return model\n",
    "\n",
    "    def net_uv(self, x, t):\n",
    "        \"\"\"Get u, v and their spatial derivatives.\"\"\"\n",
    "        X = tf.Variable(x, dtype=tf.float32)\n",
    "        T = tf.Variable(t, dtype=tf.float32)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch([X, T])\n",
    "            uv = self.build_nn(X)\n",
    "            u = uv[:, 0:1]\n",
    "            v = uv[:, 1:2]\n",
    "\n",
    "        # spatial derivatives\n",
    "        u_x = tape.gradient(u, X)\n",
    "        v_x = tape.gradient(v, X)\n",
    "\n",
    "        # # temporal derivatives\n",
    "        # u_t = tape.gradient(u, T)\n",
    "        # v_t = tape.gradient(v, T)\n",
    "\n",
    "        del tape\n",
    "\n",
    "        return u, v, u_x, v_x\n",
    "\n",
    "    def net_f_uv(self, x, t):\n",
    "        \"\"\"Compute PDE residuals.\"\"\"\n",
    "        u, v, u_x, v_x = self.net_uv(x, t)\n",
    "\n",
    "        u_t = tape.gradient(u, T)\n",
    "        v_t = tape.gradient(v, T)\n",
    "\n",
    "        u_xx = tape.gradient(u_x, X)\n",
    "        v_xx = tape.gradient(v_x, X)\n",
    "\n",
    "        f_u = u_t + 0.5*v_xx + (u**2 + v**2)*v\n",
    "        f_v = v_t - 0.5*u_xx - (u**2 + v**2)*u\n",
    "\n",
    "        return f_u, f_v\n",
    "    \n",
    "    def initialize_NN(self, layers):\n",
    "        \"\"\"\n",
    "        Initialize the weights and biases for the neural network.\n",
    "        \n",
    "        Args:\n",
    "            layers (list): List of layer sizes for the neural network\n",
    "        \"\"\"\n",
    "        weights = []\n",
    "        biases = []\n",
    "        num_layers = len(layers)\n",
    "\n",
    "        for i in range(num_layers - 1):\n",
    "            W = self.xavier_init(layers[i], layers[i+1])\n",
    "            b = tf.Variable(tf.zeros([1, layers[i+1]], dtype=tf.float32))\n",
    "            weights.append(W)\n",
    "            biases.append(b)\n",
    "\n",
    "        return weights, biases\n",
    "\n",
    "    def xavier_init(self, size_in, size_out):\n",
    "        \"\"\"\n",
    "        Initialize the weights using Xavier initialization.\n",
    "\n",
    "        Args:\n",
    "            size_in (int): Input size\n",
    "            size_out (int): Output size\n",
    "        \"\"\"\n",
    "        stddev = np.sqrt(2 / (size_in + size_out))\n",
    "        return tf.Variable(tf.random.truncated_normal([size_in, size_out], stddev=stddev))\n",
    "    \n",
    "    def compute_loss(self):\n",
    "        \"\"\"Compute the loss function.\"\"\"\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5900fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
